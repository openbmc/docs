{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "6ee20e91_dda8a77a",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000388
      },
      "writtenOn": "2022-03-18T04:26:15Z",
      "side": 1,
      "message": "The table is very hard to read and the bullets are only rendered on markdown + html viewer (visual studio or atom supports it) so please review it from a markdown viewer!",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "8a457782_869d7afe",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000016
      },
      "writtenOn": "2022-03-18T05:16:19Z",
      "side": 1,
      "message": "Have you seen the existing solutions for this? Things like hiomap and the astlpc MCTP channel, which use a shared-memory area plus some synchronisation. I feel like most of the complexities have already been handled by those.\n\n(those currently use LPC to share the memory region, but there\u0027s no reason that can\u0027t be extended to PCIe instead...)",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "a9a288ab_8c24cbb8",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2022-03-18T05:18:45Z",
      "side": 1,
      "message": "Have you thought about using this: https://github.com/openbmc/libmctp/blob/master/docs/bindings/vendor-ibm-astlpc.md ? This would give you a compliant DMTF stack for doing RDE as well.\n\nIt can be extended to use a ring buffer to queue packets.",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "b642619f_2eb11ac6",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000388
      },
      "writtenOn": "2022-03-18T17:09:05Z",
      "side": 1,
      "message": "Hi Jeremy, I didn\u0027t look through MCTP channel too thoroughly and it looks like Andrew also commented on it - looking into it, it does seem like it currently uses LPC shared memory region, which for Nuvoton is 4KB and is too small for our usecase which is why it was discounted.\n\nBut yes, if we were to extend this to use PCI Mailbox, perhaps this is something we could consider.. let me look into how that would look like, thanks for the suggestion.",
      "parentUuid": "8a457782_869d7afe",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "ce7690cf_abb6d847",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000388
      },
      "writtenOn": "2022-03-18T17:09:05Z",
      "side": 1,
      "message": "Hi Andrew, it looks like Jeremy and you had the same thoughts. As mentioned in Jeremy\u0027s comment, we discounted LPC shared memory methods due to Nuvotn\u0027s LPC shared memory buffer being only 4KB (for NPCM 7xx generation at least) which was not big enough for our usecase.\n\nI\u0027ll look into whether we can extend it to use PCI Mailbox instead, similar to how phosphor-ipmi-flash currently supports both LPC and PCI Mailbox / P2A.",
      "parentUuid": "a9a288ab_8c24cbb8",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "4d50854f_4c55cad5",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000188
      },
      "writtenOn": "2022-03-18T17:30:11Z",
      "side": 1,
      "message": "Jeremy, doesn\u0027t this require an ACK from the BMC to set up the buffer initially? I assume the goal isn\u0027t to hog the buffer from the host side in perpetuity in the event that we need the asynchronous fast access.\n\nOur requirement for this is a memory window the host can write to with no waiting on software BMC side. If we have to ask MCTP for some memory right before using it, then it does not meet this requirement.",
      "parentUuid": "b642619f_2eb11ac6",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "17c50499_4bf517a1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000388
      },
      "writtenOn": "2022-03-18T17:36:09Z",
      "side": 1,
      "message": "Initial set up requiring ack is fine (as our circular buffer header requires BMC and host side acks), however yes, if an ack is required for each memory access then that doesn\u0027t meet our requirement.\n\nI realize I didn\u0027t note that explicitly in the requirement of this doc (I noted it in some other parts of the doc), I\u0027ll add that in.",
      "parentUuid": "4d50854f_4c55cad5",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "a1fe4662_acd08673",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000388
      },
      "writtenOn": "2022-03-18T22:18:20Z",
      "side": 1,
      "message": "It looks like from https://github.com/openbmc/libmctp/blob/master/docs/bindings/vendor-ibm-astlpc.md#host-packet-transmission-sequence the TX, RX ownership transfers mean that the host won\u0027t be able to \"fire and forget\" unfortunately so I do not believe this is suitable for our usecase.",
      "parentUuid": "17c50499_4bf517a1",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "27323aee_18c54098",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2022-03-20T21:27:25Z",
      "side": 1,
      "message": "I think it\u0027s possible to introduce new features to the LPC MCTP binding such that a) it provides a ring-buffer and b) uses a polling behaviour rather than interrupt driven. I haven\u0027t given it deep thought, but it should just be the addition of head/tail offset members to the control region. The final question is whether we can observe value tearing for those members. This might happen if the LPC logic performs byte-wise reads/writes of the underlying memory words. There might be other ways to mitigate that though.",
      "parentUuid": "a1fe4662_acd08673",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "80215167_127fb840",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000388
      },
      "writtenOn": "2022-03-23T01:13:25Z",
      "side": 1,
      "message": "Problem with Nuvoton LPC is that the shared memory buffer is only 4KB which we have identified as not being enough for our usecase (we expect each payload to up to ~1KB and 4KB will overflow with 4 messages, which we\u0027re not comfortable with).\n\nAlso, another concern that was brought up was - would there be a lot of overhead in getting the host to talk MCTP? Again, I\u0027m not too familiar with MCTP and I\u0027ll have to consult the BIOS folks, but there may be limitation on what the BIOS can perform.",
      "parentUuid": "27323aee_18c54098",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7ee32695_ac14ed87",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000388
      },
      "writtenOn": "2022-03-23T01:17:22Z",
      "side": 1,
      "message": "I guess, if we\u0027re adding to MCTP to allow PCI, AND make it polling, then wouldn\u0027t it just be a completely different transport protocol?",
      "parentUuid": "80215167_127fb840",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "4213c5e0_bf9cc845",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000009
      },
      "writtenOn": "2022-03-24T00:36:41Z",
      "side": 1,
      "message": "Yeah, fair enough",
      "parentUuid": "7ee32695_ac14ed87",
      "revId": "16182ec1c0cbf883d35df4d05eb350974b217bd4",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    }
  ]
}